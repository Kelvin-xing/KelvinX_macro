{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This code cleans Code of Federal Regulations Supplement No. 4 to Part 744, Title 15, from https://www.ecfr.gov/current/title-15/subtitle-B/chapter-VII/subchapter-C/part-744/appendix-Supplement%20No.%204%20to%20Part%20744\n",
    "### It contains the list of names of certain non-US entities that are subject to specific license requirements for export, re-export or transfer of specified items by bureau of industry and security, US Department of Commerce\n",
    "### CSV version downloadable from https://www.bis.doc.gov/index.php/documents/consolidated-entity-list?format=html\n",
    "### For more details, check https://www.bis.doc.gov/index.php/policy-guidance/lists-of-parties-of-concern/entity-list\n",
    "### A search engine is available on https://www.trade.gov/consolidated-screening-list\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Historical revisions updated 2024-02-21\n",
    "dates = ['2024-02-16','2024-02-08','2024-01-29','2024-01-25','2024-01-19','2024-01-15','2024-01-10','2023-12-28','2023-12-07','2023-11-21','2023-11-17','2023-11-06','2023-10-19','2023-10-11','2023-09-27','2023-07-19','2023-06-21','2023-06-14','2023-05-22','2023-04-26','2023-04-17','2023-03-30','2023-03-14','2023-03-06','2023-02-27','2023-02-14','2023-02-01','2022-12-23','2022-12-19','2022-12-16','2022-12-08','2022-10-21','2022-10-13','2022-10-07','2022-10-04','2022-09-16','2022-09-09','2022-08-24','2022-06-30','2022-06-06','2022-06-01','2022-05-11','2022-04-11','2022-04-07','2022-03-16','2022-03-09','2022-03-08','2022-03-03','2022-02-14','2022-02-03','2021-12-17','2021-11-26','2021-11-04','2021-10-05','2021-08-20','2021-07-21','2021-07-19','2021-07-12','2021-07-06','2021-06-24','2021-06-16','2021-06-01','2021-04-09','2021-03-16','2021-03-08','2021-03-04','2021-01-15','2020-12-23','2020-12-22','2020-10-30','2020-10-19','2020-09-22','2020-09-11','2020-08-27','2020-08-20','2020-07-22','2020-06-18','2020-06-05','2020-05-19','2020-03-16','2020-03-02','2019-12-18','2019-12-06','2019-11-13','2019-10-21','2019-10-09','2019-08-21','2019-08-14','2019-06-24','2019-05-24','2019-05-21','2019-05-14','2019-04-11','2018-12-20','2018-10-30','2018-09-26','2018-09-12','2018-09-04','2018-08-30','2018-08-01','2018-03-22','2018-02-16','2018-01-26','2017-12-20','2017-09-25','2017-06-30','2017-06-22','2017-05-26','2017-04-18','2017-03-29','2017-03-16']\n",
    "\n",
    "## File under cleaning process\n",
    "# Note: Can loop over dates, but special treatment in the next block suiting only up to 2023-11-21\n",
    "date = dates[0]\n",
    "url = f\"https://www.ecfr.gov/api/versioner/v1/full/{date}/title-15.xml?appendix=Supplement+No.+4+to+Part+744&part=744\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! Irregular of table happens in row(s) [283, 284, 285, 496, 507, 1674]\n",
      "There are 2712 entities in total.\n"
     ]
    }
   ],
   "source": [
    "# table\n",
    "soup = bs(response.text,features='lxml')\n",
    "find_table = soup.find('table')\n",
    "\n",
    "# header\n",
    "headers = find_table.find_all('th')\n",
    "headers = [header.text.replace('\\n',' ').strip() for header in headers]\n",
    "df = pd.DataFrame(columns=headers)\n",
    "\n",
    "# data\n",
    "rows = find_table.find_all('tr')\n",
    "filtered_df = pd.DataFrame() # working dataframe in debugging\n",
    "list = [] # to check structural problem with the table\n",
    "irregular = [] # to track unexpectedly empty cells\n",
    "for row in rows:\n",
    "    table_data = row.find_all('td')\n",
    "    list.append(len(table_data))\n",
    "    data = {header:j.text.strip() for j, header in zip(table_data, headers)}\n",
    "    data = pd.DataFrame(data,index=[0])\n",
    "    df = pd.concat([df, data],axis=0,ignore_index=True)\n",
    "df = df.drop([0])\n",
    "list = list[1:]\n",
    "\n",
    "## special treatment of irregular rows\n",
    "# check irregular table structure rows\n",
    "for i in range(len(list)):\n",
    "    if not list[i] == 5:\n",
    "        irregular.append(i)\n",
    "for index, row in df.iterrows():\n",
    "    if not len(df.loc[index,'Federal Register citation']):\n",
    "        irregular.append(index)\n",
    "irregular.sort()\n",
    "# show warning\n",
    "print(f\"Warning! Irregular of table happens in row(s) {irregular}\")\n",
    "\n",
    "# treatment of China Aerospace Science and Industry Corporation Second Academy and its subordinates, row 282-285\n",
    "ind = df[df['Entity'].str.contains('China Aerospace Science and Industry Corporation Second Academy')].index[0]\n",
    "df['Entity'][ind] = df['Entity'][ind] + '\\n' + df['Entity'][ind+1] + '\\n' + df['Entity'][ind+2] + '\\n' + df['Entity'][ind+3]\n",
    "df = df.drop([ind + i for i in range(1,4)]).reset_index(drop=True)\n",
    "\n",
    "# treatment of Huawei and its affiliated entities, row 496\n",
    "ind = df[df['Entity'].str.contains('Affiliated entities')].index[0]\n",
    "df['Entity'][ind-1] = df['Entity'][ind-1] + '\\n' + df['Entity'][ind]\n",
    "df = df.drop([ind]).reset_index(drop=True)\n",
    "\n",
    "# wrong new line of ICSOSO, row 502\n",
    "ind = df[df['Entity'].str.contains('ICSOSO')].index[0]\n",
    "df['Entity'][ind] = df['Entity'][ind] + df['Entity'][ind+1]\n",
    "df['License requirement'][ind] = df['License requirement'][ind+1]\n",
    "df['License review policy'][ind] = df['License review policy'][ind+1]\n",
    "df['Federal Register citation'][ind] = df['Federal Register citation'][ind+1]\n",
    "df = df.drop([ind+1]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# fill empty fed registration rate, row 507\n",
    "df.loc[df['Entity'].str.contains('ICSOSO'),'Federal Register citation'] = '87 FR 38925, 6/30/22.' # checked manually on https://www.federalregister.gov/documents/2023/09/27/2023-21080/addition-of-entities-and-revision-to-existing-entities-on-the-entity-list-removal-of-existing-entity\n",
    "\n",
    "# treatment of irregular address, row 1674\n",
    "ind = df.loc[df['Entity'].str.contains('Institute of Physics Named After P.N. Lebedev of the Russian Academy of Sciences')].index[0]\n",
    "df['Entity'][ind] = df['Entity'][ind] + '\\n\\n' + df['Entity'][ind+1]\n",
    "df = df.drop([ind+1]).reset_index(drop=True)\n",
    "\n",
    "## treatment of Aerofalcon, row 2389\n",
    "## This part solved later by the database\n",
    "# mislocation_text = 'Aerofalcon'\n",
    "# ind = df[df['License requirement'].str.contains(mislocation_text)].index\n",
    "# grandchild = soup.find_all(lambda tag: len(tag.find_all()) == 0 and mislocation_text in tag.text)[0]\n",
    "# country = grandchild.find_previous_siblings()[1].text\n",
    "# table_data = grandchild.find_next_siblings()\n",
    "# data = {\n",
    "#     headers[0]:country,\n",
    "#     headers[1]:grandchild.text,\n",
    "#     headers[2]:table_data[0].text,\n",
    "#     headers[3]:table_data[1].text,\n",
    "#     headers[4]:table_data[2].text\n",
    "# }\n",
    "# for key, value in data.items():\n",
    "#     df.loc[ind,key] = value.strip()\n",
    "\n",
    "## Report total number of entities:\n",
    "print(f\"There are {len(df)} entities in total.\")\n",
    "\n",
    "## Fill down country\n",
    "df['Country'] = df['Country'].replace('',np.nan).ffill(axis=0)\n",
    "\n",
    "## Sanitize encoding problem\n",
    "# the xml is in utf-8 but jupyter notebook processes and decodes it and saves it into csv in an ASCII way\n",
    "# problems in License requirement\n",
    "df['License requirement'] = df['License requirement'].str.replace('\\xc2\\xa7','section') # section symbol §\n",
    "\n",
    "# problems in License review policy\n",
    "df['License review policy'] = (df['License review policy']\n",
    "                               .str.replace('\\xc2\\xa7\\xc2\\xa7','\\xc2\\xa7') # section symbol §\n",
    "                               .str.replace('\\xc2\\xa7','section')) # section symbol §\n",
    "\n",
    "# problems in Entity\n",
    "clean_entity = {\n",
    "    '\\xE2\\x80\\x94':'-', # em dash into minus\n",
    "    '\\xE2\\x80\\x93':'-', # en dash into minus\n",
    "    '\\xE2\\x80\\x90':'-', # hyphen into minus\n",
    "    '\\xE2\\x80\\x9C':'\\\"', # double turned comma quotation into quotation\n",
    "    '\\xE2\\x80\\x9D':'\\\"', # double comma quotation into quotation\n",
    "    '\\xc2\\xba':'', # MASCULINE ORDINAL INDICATOR\n",
    "    '\\xc3\\x81':'A', # Á into A\n",
    "    '\\xc3\\x89':'E', # É into E\n",
    "    '\\xc3\\xa1':'a', # á into a\n",
    "    '\\xc3\\xa3':'a', # ã into a\n",
    "    '\\xc3\\xa4':'ae', # ä into ae\n",
    "    '\\xc3\\xa9':'e', # é into e\n",
    "    '\\xc3\\xb3':'o', # ó into o\n",
    "    '\\xc3\\xb5':'o', # õ into o\n",
    "    '\\xc3\\xb6':'o', # ö into o\n",
    "    '\\xc3\\xbc':'ue', # ü into ue\n",
    "    '\\xc5\\x9e':'S', # Ş into S\n",
    "    '\\xc5\\x9f':'s', # ş into s\n",
    "}\n",
    "for key, item in clean_entity.items():\n",
    "    df['Entity'] = df['Entity'].str.replace(key,item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Get the name, alias, address and subordinate pattern with OpenAi\n",
    "# import openai\n",
    "# client = openai.OpenAI()\n",
    "\n",
    "# completion = client.chat.completions.create(\n",
    "#     model = 'gpt-3.5-turbo-1106',\n",
    "#     messages = [\n",
    "#         # {\n",
    "#         #     'role':'system',\n",
    "#         #     'content':'You will be given a series of strings that is a column of a dataframe. Your job is to read the strings, classify entity name, alias, subordinate/ affiliate and address, and conclude patterns of each classification in regular expression. You can try to classify the four elements by whether there exists either of them in the strings.'\n",
    "#         # },\n",
    "#         # {\n",
    "#         #     'role':'user',\n",
    "#         #     'content':f\"The series to read is {df['Entity']}. Since the subordinates may also have aliases, and that there may be entities with neither subordinates nor aliases, you can first try to separate out name, and extract subordinates from the rest of the str ing, and extract alias of the entity but leave the alias of subordinates together into the list of subordinates, and finally get the address.\"\n",
    "#         # }\n",
    "#         {\n",
    "#             'role':'user',\n",
    "#             'content':f\"read string {df['Entity'][303]},{df['Entity'][431]} and {df['Entity'][434]}. jupyter notebook displays what should have been dash, hyphen or minus as 'â\\x80\\x94' or 'â' where the space is not space but something else unknown. Tell me what it is\"\n",
    "#         }\n",
    "#     ],\n",
    "#     temperature=0,\n",
    "#     # max_tokens=256,\n",
    "#     top_p=1,\n",
    "#     frequency_penalty=0,\n",
    "#     presence_penalty=0\n",
    "# )\n",
    "\n",
    "# pd.options.display.max_colwidth = 1000000\n",
    "# # with open('gpt_create_pattern.py', 'w') as file:\n",
    "# #     file.write(completion.choices[0].message.content)\n",
    "# print(completion.choices[0].message.content)\n",
    "# print(completion.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2698 independent entities in total.\n"
     ]
    }
   ],
   "source": [
    "## Split Entity for name, address, alias, and subordinates\n",
    "# Initialize Name, Address, Alias and Subordinate\n",
    "df['Name'] = df['Alias'] = df['Address'] = df['Subordinate'] = 'NaN'\n",
    "\n",
    "# identify two entities which are subordinates of CETC-7\n",
    "destin_index = df[df['Entity'].str.contains('\\(CETC-7\\)')].index.item()\n",
    "sub_indices = df[df['Entity'].str.contains('CETC-7',regex=False)].index.to_list()[1:]\n",
    "df['Subordinate'][destin_index] = []\n",
    "for i in range(len(sub_indices)):\n",
    "    index = sub_indices[i]\n",
    "    # sub = re.split(r\"\\(a subordinate institute\",df['Entity'][index])[0]\n",
    "    sub = df['Entity'][index]\n",
    "    df['Subordinate'][destin_index].append(sub)\n",
    "    df = df.drop(index)\n",
    "\n",
    "# identify subordinates of CETC 13\n",
    "indices = df[df['Entity'].str.contains('\\(CETC 13\\)')].index.to_list()\n",
    "destin_index = indices[0]\n",
    "sub_indices = indices[1:]\n",
    "df['Subordinate'][destin_index] = []\n",
    "for i in range(len(sub_indices)):\n",
    "    index = sub_indices[i]\n",
    "    sub = re.split(r\"subordinate institution:\\n?\",df['Entity'][index])[1]\n",
    "    # sub = df['Entity'][index]\n",
    "    df['Subordinate'][destin_index].append(sub)\n",
    "    df = df.drop(index)\n",
    "\n",
    "# printing total number of independent entities in total\n",
    "print(f\"There are {len(df)} independent entities in total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "## special treatment of irregular entities w.r.t. alias\n",
    "\n",
    "# 1) for those with parentheses around the alias\n",
    "# Mesbah Energy Company\n",
    "ind = df.loc[df['Entity'].str.contains('Mesbah Energy Company')].index[0]\n",
    "df['Entity'][ind] = re.sub(' \\(a.k.a. \"MEC\"\\)','(MEC)',df['Entity'][ind])\n",
    "\n",
    "# Parto System Tehran\n",
    "ind = df.loc[df['Entity'].str.contains('Parto System Tehran')].index[0]\n",
    "df['Entity'][ind] = re.sub(r'\\s\\(a.k.a., Rayan Parto System Tehran and Rayane Parto System Tehran\\),',' a.k.a., the following two aliases:\\n-Rayan Parto System Tehran; and\\n-Rayane Parto System Tehran\\n\\n',df['Entity'][ind])\n",
    "\n",
    "# Paya Electronics Complex\n",
    "ind = df.loc[df['Entity'].str.contains('Paya Electronics Complex')].index[0]\n",
    "df['Entity'][ind] = re.sub(r'\\s\\(a.k.a., Paya Complex\\), ',' a.k.a., the following one alias:\\n-Paya Complex\\n\\n',df['Entity'][ind])\n",
    "\n",
    "# Sabanican Company\n",
    "ind = df.loc[df['Entity'].str.contains('Sabanican Company')].index[0]\n",
    "df['Entity'][ind] = re.sub(r'\\s\\(a.k.a., Sabanican Pad Co.\\),',', a.k.a., the following one alias:\\n-Sabanican Pad Co.\\n\\n',df['Entity'][ind])\n",
    "\n",
    "# Iman Group\n",
    "ind = df.loc[df['Entity'].str.contains('Iman Group')].index[0]\n",
    "df['Entity'][ind] = re.sub(', a.k.a., the following one\\nalias:',', a.k.a., the following one alias:',df['Entity'][ind])\n",
    "\n",
    "# Almaz-Antey Air Defense Concern Main System Design Bureau\n",
    "ind = df.loc[df['Entity'].str.contains('Almaz-Antey Air Defense Concern Main System Design Bureau')].index[0]\n",
    "df['Entity'][ind] = re.sub(r' a.k.a. GSKB\\)',' a.k.a. GSKB',df['Entity'][ind])\n",
    "df['Entity'][ind] = re.sub(' a.k.a.','\\n-',df['Entity'][ind])\n",
    "df['Entity'][ind] = re.sub(' f.k.a., ','\\n-',df['Entity'][ind])\n",
    "df['Entity'][ind] = re.sub(r'\\s\\(a.k.a.,',', a.k.a., the following two aliases:',df['Entity'][ind])\n",
    "\n",
    "# Kalinin Machine Plant\n",
    "ind = df.loc[df['Entity'].str.contains('Kalinin Machine Plant')].index[0]\n",
    "df['Entity'][ind] = re.sub(r' Ekaterinburg\\)',' Ekaterinburg',df['Entity'][ind])\n",
    "df['Entity'][ind] = re.sub(' a.k.a.','\\n-',df['Entity'][ind])\n",
    "df['Entity'][ind] = re.sub(r'\\s\\(a.k.a.,',', a.k.a., the following two aliases:',df['Entity'][ind])\n",
    "\n",
    "# Mytishchinski Mashinostroitelny Zavod, OAO\n",
    "ind = df.loc[df['Entity'].str.contains('Mytishchinski Mashinostroitelny Zavod, OAO')].index[0]\n",
    "df['Entity'][ind] = re.sub(r\" Mashinostroitelny ZAVOD'\\)\",\" Mashinostroitelny ZAVOD'\",df['Entity'][ind])\n",
    "df['Entity'][ind] = re.sub(' a.k.a.','\\n-',df['Entity'][ind])\n",
    "df['Entity'][ind] = re.sub(r'\\s\\(a.k.a.,',', a.k.a., the following two aliases:',df['Entity'][ind])\n",
    "\n",
    "# Tikhomirov Scientific Research Institute of Instrument Design\n",
    "ind = df.loc[df['Entity'].str.contains('Tikhomirov Scientific Research Institute of Instrument Design')].index[0]\n",
    "df['Entity'][ind] = re.sub(r\" Design.\\)\",\" Design.'\",df['Entity'][ind])\n",
    "df['Entity'][ind] = re.sub(' a.k.a.','\\n-',df['Entity'][ind])\n",
    "df['Entity'][ind] = re.sub(' f.k.a., ','\\n-',df['Entity'][ind])\n",
    "df['Entity'][ind] = re.sub(r'\\s\\(a.k.a.,',', a.k.a., the following two aliases:',df['Entity'][ind])\n",
    "\n",
    "# Wong Yuh Lan\n",
    "ind = df.loc[df['Entity'].str.contains('Wong Yuh Lan')].index[0]\n",
    "df['Entity'][ind] = re.sub(r'\\s\\(a.k.a.,',', a.k.a., the following two aliases:',df['Entity'][ind])\n",
    "df['Entity'][ind] = re.sub(r\" Huang Yulan, Jancy Wong and Yuh Lan Wong\\),\",\"\\n-Huang Yulan;\\n-Jancy Wong; and\\n-Yuh Lan Wong\\n\\n\",df['Entity'][ind])\n",
    "\n",
    "# Aletra General Trading\n",
    "ind = df.loc[df['Entity'].str.contains('Aletra General Trading')].index[0]\n",
    "df['Entity'][ind] = re.sub(r'\\s\\(a.k.a.,',', a.k.a., the following two aliases:',df['Entity'][ind])\n",
    "df['Entity'][ind] = re.sub(r\"Erman & Sultan Trading Co.\\), \",\"\\n-Erman & Sultan Trading Co.\\n\\n\",df['Entity'][ind])\n",
    "\n",
    "# 2) rows with a.k.a./ f.k.a. as delimiter of alias\n",
    "aka_entities = ['Dolgoprudny Research Production Enterprise','Gazprom Neft','Gazprom, OAO','Lukoil, OAO','Rosneft\\s\\(','Open Joint Stock Company Surgutneftegas']\n",
    "for entity in aka_entities:\n",
    "    ind = df.loc[df['Entity'].str.contains(entity)].index[0]\n",
    "    df['Entity'][ind] = re.sub(r'f.k.a.','\\n-',df['Entity'][ind])\n",
    "    df['Entity'][ind] = re.sub(r'a.k.a.','\\n-',df['Entity'][ind])\n",
    "    df['Entity'][ind] = re.sub(r'\\s\\(',', a.k.a., the following several aliases:',df['Entity'][ind])\n",
    "    df['Entity'][ind] = re.sub(r'\\)','',df['Entity'][ind])\n",
    "\n",
    "# 3.1) rows with comma as delimiter of alias, with street in address\n",
    "comma_entities_1 = ['Encyclopedia Electronics Center','Industrial Establishment of Defense']\n",
    "# Encyclopedia Electronics Center\n",
    "ind = df.loc[df['Entity'].str.contains('Encyclopedia Electronics Center')].index[0]\n",
    "result = re.split(', Mosalam Baroudi Street,', df['Entity'][ind],)\n",
    "temp_entity, temp_address = result\n",
    "temp_address = '\\n\\nMosalam Baroudi Street,' + temp_address\n",
    "result = re.split(', a.k.a.,', temp_entity)\n",
    "name, temp_alias = result\n",
    "name = name + ', a.k.a., the following several aliases:\\n-'\n",
    "temp_alias = re.sub('\\,',';\\n-',temp_alias)\n",
    "df['Entity'][ind] = name + temp_alias + temp_address\n",
    "\n",
    "# Industrial Establishment of Defense\n",
    "ind = df.loc[df['Entity'].str.contains('Industrial Establishment of Defense')].index[0]\n",
    "result = re.split(', Al Thawraa Street,', df['Entity'][ind],)\n",
    "temp_entity, temp_address = result\n",
    "temp_address = '\\n\\nAl Thawraa Street,' + temp_address\n",
    "result = re.split(', a.k.a.,', temp_entity)\n",
    "name, temp_alias = result\n",
    "name = name + ', a.k.a., the following several aliases:\\n-'\n",
    "temp_alias = re.sub('\\,',';\\n-',temp_alias)\n",
    "df['Entity'][ind] = name + temp_alias + temp_address\n",
    "\n",
    "# 3.2) rows with comma as delimiter of alias, without street in address\n",
    "comma_entities_2 = ['Higher Institute of Applied Science and Technology','Scientific Studies and Research Center \\(SSRC\\),','National Standards and Calibration Laboratory']\n",
    "for entity in comma_entities_2:\n",
    "    ind = df.loc[df['Entity'].str.contains(entity)].index[0]\n",
    "    result = re.split(', P.O.', df['Entity'][ind])\n",
    "    temp_entity, temp_address = result\n",
    "    temp_address = '\\n\\nP.O.' + temp_address\n",
    "    result = re.split(', a.k.a.,', temp_entity)\n",
    "    name, temp_alias = result\n",
    "    name = name + ', a.k.a., the following several aliases:\\n-'\n",
    "    temp_alias = re.sub('\\,',';\\n-',temp_alias)\n",
    "    df['Entity'][ind] = name + temp_alias + temp_address\n",
    "\n",
    "# 4) idiosyncratic cleaning\n",
    "# Engineering Materials and Equipment Co.\n",
    "ind = df.loc[df['Entity'].str.contains('Engineering Materials and Equipment Co\\.')].index[0]\n",
    "df['Entity'][ind] = re.sub('\\n\\n-EMEC,','\\n-EMEC\\n\\n',df['Entity'][ind])\n",
    "\n",
    "# Joseph Choi, aka Yo-so'p Ch'oe,\n",
    "ind = df.loc[df['Entity'].str.contains(\"Joseph Choi, aka Yo-so'p Ch'oe\")].index[0]\n",
    "df['Entity'][ind] = re.sub(r\"Joseph Choi, aka Yo-so\\'p Ch\\'oe,\",'Joseph Choi, a.k.a., the following one alias:\\n- Yosop Choe\\n\\n',df['Entity'][ind])\n",
    "\n",
    "# Presto Freight International LLC.\n",
    "ind = df.loc[df['Entity'].str.contains(\"Presto Freight International LLC\")].index[0]\n",
    "df['Entity'][ind] = re.sub(r\"aka Presto Freight International LLC \\(PFI\\), \",'a.k.a., the following one alias:\\n-Presto Freight International LLC (PFI)\\n\\n',df['Entity'][ind])\n",
    "\n",
    "# Manufacturers Equipment Organization (MEO)\n",
    "ind = df.loc[df['Entity'].str.contains(\"Manufacturers Equipment Organization\")].index[0]\n",
    "df['Entity'][ind] = re.sub(r\"following one alias\\: -MEO GMBH P\\.O\",'following one alias:\\n-MEO GMBH\\n\\nP.O',df['Entity'][ind])\n",
    "\n",
    "# JLD Technology\n",
    "ind = df.loc[df['Entity'].str.contains(\"JLD Technology, Hong Kong\")].index[0]\n",
    "df['Entity'][ind] = re.sub(r\"JLD Technology, Hong Kong Co\\. Ltd\",'JLD Technology Hong Kong Co. Ltd',df['Entity'][ind])\n",
    "\n",
    "# Abbas Goldoozan\n",
    "ind = df.loc[df['Entity'].str.contains(\"JLD Technology, Hong Kong\")].index[0]\n",
    "df['Entity'][ind] = re.sub(r\"Abbas Goldoozan, Kimya\",'Abbas Goldoozan Kimya',df['Entity'][ind])\n",
    "\n",
    "# Thomas McGuinn\n",
    "ind = df.loc[df['Entity'].str.contains(\"Thomas McGuinn\")].index[0]\n",
    "df['Entity'][ind] = re.sub(r\"Thomas McGuinn a\",'Thomas McGuinn, a',df['Entity'][ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "## special treatment of irregular entities w.r.t. address\n",
    "# Kral Aviation\n",
    "ind = df.loc[df['Entity'].str.contains('Kral Aviation Ltd\\. Senlikkoy Mah\\,')].index[0]\n",
    "df['Entity'][ind] = re.sub('Kral Aviation Ltd\\. Senlikkoy Mah\\,','Kral Aviation Ltd\\.\\, Senlikkoy Mah\\,',df['Entity'][ind])\n",
    "\n",
    "# Xinnlinx Electronics Pte Ltd\n",
    "ind = df.loc[df['Entity'].str.contains('Xinnlinx Electronics Pte Ltd,')].index[0]\n",
    "df['Entity'][ind] = re.sub('Xinnlinx Electronics Pte Ltd,','Xinnlinx Electronics Pte Ltd.,',df['Entity'][ind])\n",
    "\n",
    "# Bel Huawei Technologies\n",
    "ind = df.loc[df['Entity'].str.contains('Bel Huawei Technologies LLC')].index[0]\n",
    "df['Entity'][ind] = re.sub('BellHuawei Technologies LLC. 5','BellHuawei Technologies LLC.\\n\\n 5',df['Entity'][ind])\n",
    "\n",
    "# CJSC Zest\n",
    "ind = df.loc[df['Entity'].str.contains('Zest Leasing')].index[0]\n",
    "df['Entity'][ind] = re.sub('Zest Leasing\\n','Zest Leasing\\n\\n',df['Entity'][ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name only entities\n",
    "name_only_entities = ['The following Department of Atomic Energy entities', 'Ali Mehdipour Omrani', 'Aref Bali Lashak', 'Kamran Daneshjou', 'Mehdi Teranchi', 'Sayyed Mohammad Mehdi Hadavi', r'Allied Trading Co$', 'Prime International', 'Unique Technical Promoters', 'Brian Douglas Woodford']\n",
    "name_only_index = [df.loc[df['Entity'].str.contains(entity)].index[0] for entity in name_only_entities]\n",
    "filtered_df = pd.DataFrame()\n",
    "\n",
    "# drop comma before certain patterns\n",
    "drop_comma = {\n",
    "    r',\\sI?i?nc\\.':' Inc.',\n",
    "    r',\\sLTD\\.': ' Ltd.',\n",
    "    r',\\sLtd\\.': ' Ltd.',\n",
    "    r',\\sltd\\.': ' Ltd.',\n",
    "    r',\\sLtd': ' Ltd.',\n",
    "    r',\\sLLC':' LLC.',\n",
    "    r',\\sLimited\\.?': 'Limited',\n",
    "    r',\\sLtd\\s\\(HiSilicon\\)':' Ltd (HiSilicon)',\n",
    "    r', S\\.A\\.': ' S.A.',\n",
    "    r',\\sOOO': ' OOO'\n",
    "}       \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # clean entity\n",
    "    # remove see 'alternate addresses' part\n",
    "    df['Entity'][index] = re.sub(r\"\\(S?s?ee (A?a?lternate|also) addresse?s? \\b(under|in)\\b .+\\)\\.?\",\"\",df['Entity'][index])\n",
    "\n",
    "    # jump for name only entities:\n",
    "    if index in name_only_index:\n",
    "        df['Name'][index] = df['Entity'][index]\n",
    "        continue\n",
    "\n",
    "    # drop comma before certain patterns\n",
    "    for key, item in drop_comma.items():\n",
    "        df['Entity'][index] = re.sub(key,item,df['Entity'][index])\n",
    "\n",
    "    # standardize 'a.k.a., the following .* alias'\n",
    "    # special treatment with more than one appearance\n",
    "    df['Entity'][index] = re.sub(r' \\(a.k.a., NEL Electronics Pte Ltd\\),',' a.k.a., the following one alias:\\n-NEL Electronics Pte Ltd\\n\\n',df['Entity'][index])\n",
    "    df['Entity'][index] = re.sub(r'\\s\\(a.k.a.,? Lin Rongnan, Steven Lim and Yong Nam Lim\\)',' a.k.a., the following three aliases:\\n-Lin Rongnan;\\n-Steven Lim; and\\n-Yong Nam Lim\\n\\n',df['Entity'][index])\n",
    "\n",
    "    # more general cases\n",
    "    df['Entity'][index] = re.sub(r\"including the following alias\", \"the following one alias\",df['Entity'][index]) \n",
    "    df['Entity'][index] = re.sub(r\"the following (\\w+) entity\", r\"the following \\1 alias\",df['Entity'][index]) \n",
    "    df['Entity'][index] = re.sub(r\"the following alias\",\"the following one alias\",df['Entity'][index])\n",
    "    df['Entity'][index] = re.sub(r\"and the following (\\w+) aliases\", \"a.k.a., the following \\1 alias\",df['Entity'][index])\n",
    "    df['Entity'][index] = re.sub(r\"the follow three aliases\", \"the following three aliases\",df['Entity'][index])\n",
    "    df['Entity'][index] = re.sub(r\"a\\.k\\.a\\., following two aliases\", \"a.k.a., the following two aliases\",df['Entity'][index])\n",
    "    df['Entity'][index] = re.sub(r\"a\\.k\\.a\\., the one alias\", \"a.k.a., the following one alias\",df['Entity'][index])\n",
    "    df['Entity'][index] = re.sub(r\", a\\.k\\.a\\., as the following two aliases\", \", a.k.a., the following two aliases\",df['Entity'][index])\n",
    "    df['Entity'][index] = re.sub(r\"a.k.a.?,? the following (\\w+) alias\", r\", a.k.a., the following \\1 alias\",df['Entity'][index])\n",
    "    df['Entity'][index] = re.sub(r\"a.k.a.?,? the following (\\w+) alias,\", r\", a.k.a., the following \\1 alias:\",df['Entity'][index])\n",
    "    df['Entity'][index] = re.sub(r\"a.k.a. the following (\\w+) alias\", r\", a.k.a., the following \\1 alias\",df['Entity'][index])\n",
    "    df['Entity'][index] = re.sub(r\"a.k.a., the following (\\w+) aliases\\n\", r\", a.k.a., the following \\1 aliases:\\n\",df['Entity'][index])\n",
    "    if 'a.k.a' in df['Entity'][index] and not 'the following' in df['Entity'][index]:\n",
    "        df['Entity'][index] = re.sub(r\"a\\.k\\.a\\.?,?\", \"a.k.a., the following one alias:\\n-\",df['Entity'][index])\n",
    "    if 'the following' in df['Entity'][index] and not 'a.k.a.' in df['Entity'][index]:\n",
    "        df['Entity'][index] = re.sub(r\"the following\", \", a.k.a., the following\",df['Entity'][index])\n",
    "    \n",
    "    # Idea: first get subordinates with 'subordinate institutions., then alias. Note that only in the occasion of 'subordinate institutions' are there extra characters after 'the following (\\w) alias(es)?:', that is, the only case that does not obey the pattern that splits name and aliases.\n",
    "    if 'subordinate institution' in df['Entity'][index].lower():\n",
    "        name_pattern = r', a\\.k\\.a\\., the following .* aliase?s?, .* subordinate institutions:'\n",
    "        result = re.split(name_pattern,df['Entity'][index])\n",
    "        if len(result) == 2:\n",
    "            df['Name'][index], temp = result\n",
    "            result = re.split(r\"\\bS?s?ubordinate i?I?nstitution\\b:?\", temp)\n",
    "            if len(result) == 3:\n",
    "                df['Subordinate'][index] = [result[1].strip()]\n",
    "                temp_alias = result[0].strip()\n",
    "                temp_address = result[2].strip()\n",
    "            else:\n",
    "                df['Subordinate'][index] = result[1:-1]\n",
    "                temp_alias = result[0].strip()\n",
    "                temp_address = result[-1].strip()\n",
    "            # get alias\n",
    "            if '\\n-' in temp_alias:\n",
    "                result = re.split(r'\\n\\-',temp_alias)\n",
    "                if len(result) == 1:\n",
    "                    df['Alias'][index] = result[0].strip()\n",
    "                else:\n",
    "                    if result[0] == '':\n",
    "                        df['Alias'][index] = result[1:]\n",
    "                    else:\n",
    "                        df['Alias'][index] = result[0:]\n",
    "            else: \n",
    "                df['Alias'][index] = temp_alias\n",
    "            # get address\n",
    "            if 'the following addresses apply to the entity' in temp_address.lower():\n",
    "                address_pattern = 'The following addresses apply to the entity and .* subordinate institutions:\\n?\\n?'\n",
    "                result = re.split(address_pattern,temp_address)\n",
    "                if len(result) == 2:\n",
    "                    temp_subordinate, df['Address'][index] = result\n",
    "                    df['Subordinate'][index].append(temp_subordinate)\n",
    "            else:\n",
    "                result = re.split(r'\\n\\n',temp_address)\n",
    "                temp_subordinate, df['Address'][index] = result\n",
    "                df['Subordinate'][index].append(temp_subordinate)\n",
    "        continue\n",
    "\n",
    "\n",
    "    # possible delimiter for address: \\n\\n, comma, 'The following addresses apply to the entity and the two subordinate institutions:'; \n",
    "    # for name: 'a.k.a., the following', comma, 'subordinate institution'; \n",
    "    # for subordinates: 'subordinate institution', minus sign; \n",
    "    # for alias: minus sign.\n",
    "    try:\n",
    "        # split entity\n",
    "        # with 'a.k.a., the following XXX alias(es):' get name\n",
    "        name_pattern = r', a\\.k\\.a\\., the following .* aliase?s?:'\n",
    "        result = re.split(name_pattern, df['Entity'][index],1)\n",
    "        if len(result) == 2:# case where there is alias\n",
    "            df['Name'][index], temp = result\n",
    "            # get subordinate\n",
    "            if 'subordinate entit' in temp.lower():\n",
    "                result = re.split(r'; and the following four subordinate entities:\\n',temp)\n",
    "                df['Alias'][index], temp_subordinate = result\n",
    "                df['Alias'][index] = [df['Alias'][index]]\n",
    "                # get address and subordinate\n",
    "                result = re.split(r'\\n\\n',temp_subordinate)\n",
    "                df['Subordinate'][index] = result[0].strip() + result[1].strip()\n",
    "                # df['Subordinate'][index] = [df['Subordinate'][index]]\n",
    "                df['Address'][index] = result[2].strip()\n",
    "            elif 'affiliated entities:' in temp.lower():\n",
    "                df['Entity'][index] = re.sub(', and to include the following addresses and the following 22 affiliated entities:','', df['Entity'][index])# huawei row 491\n",
    "                # get subordinate\n",
    "                temp, df['Subordinate'][index] = re.split(r'Affiliated entities:\\n',temp)\n",
    "                # get address\n",
    "                temp_alias, df['Address'][index] = re.split(r'\\n\\n',temp)\n",
    "                # get alias\n",
    "                if '\\n-' in temp_alias:\n",
    "                    result = re.split(r'\\n\\-',temp_alias)\n",
    "                    if len(result) == 1:\n",
    "                        df['Alias'][index] = result[0].strip()\n",
    "                    else:\n",
    "                        if result[0] == '':\n",
    "                            df['Alias'][index] = result[1:]\n",
    "                        else:\n",
    "                           df['Alias'][index] = result[0:]\n",
    "                else: \n",
    "                    df['Alias'][index] = [temp_alias]\n",
    "            else: # case where there is alias but no subordinates\n",
    "                # get address\n",
    "                result = re.split(r'\\n\\n',temp) #\\n\\n as delimiter for address\n",
    "                if len(result) == 2:\n",
    "                    temp_alias, df['Address'][index] = result\n",
    "                else:\n",
    "                    result = re.split(r'\\,',temp,1) # comma as delimiter for address\n",
    "                    if len(result) == 2:\n",
    "                        temp_alias, df['Address'][index] = result\n",
    "                    else:\n",
    "                        result = re.split(r'\\.',temp,1) # period as delimiter for address\n",
    "                        if len(result) == 2:\n",
    "                            temp_alias, df['Address'][index] = result\n",
    "                        else:\n",
    "                            filtered_df = pd.concat([filtered_df,row],axis=1).transpose() # to be fixed individually\n",
    "                # get alias\n",
    "                if '\\n-' in temp_alias: # multiple aliases or '-' as delimiter\n",
    "                    result = re.split(r'\\n\\-',temp_alias)\n",
    "                    if len(result) == 1:\n",
    "                        df['Alias'][index] = result[0].strip()\n",
    "                    else:\n",
    "                        if result[0] == '':\n",
    "                            df['Alias'][index] = result[1:]\n",
    "                        else:\n",
    "                           df['Alias'][index] = result[0:]\n",
    "                else: # one alias only with no '-' as delimiter\n",
    "                    df['Alias'][index] = [temp_alias]\n",
    "        else: # case where there is no alias\n",
    "            name_pattern = r'\\,'\n",
    "            result = re.split(name_pattern,df['Entity'][index],1)\n",
    "            if len(result) == 2:\n",
    "                df['Name'][index], temp = result\n",
    "                # get address with \\n\\n\n",
    "                result = re.split(r'\\n\\n',temp)\n",
    "                if len(result) == 2:\n",
    "                    df['Address'][index] = result[1]\n",
    "                else:\n",
    "                    df['Address'][index] = temp.strip() # there is only entity name and address available\n",
    "            else:\n",
    "                name_pattern = r'\\n\\n'\n",
    "                result = re.split(name_pattern,df['Entity'][index])\n",
    "                if len(result) == 2:\n",
    "                    df['Name'][index], df['Address'][index] = result\n",
    "    except:\n",
    "        print(f\"An exception occurred on row {index}\")\n",
    "\n",
    "if not len(filtered_df) == 0:\n",
    "    print(f\"There are problems w.r.t. address and alias in entities in the following dataframe: {filtered_df}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean name, alias, subordinate and address\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        # Cleaning Name\n",
    "        df['Name'][index] = df['Name'][index].rstrip(', ')\n",
    "\n",
    "        # Cleaning alias\n",
    "        if not df['Alias'][index] == 'NaN':\n",
    "            df['Alias'][index] = [x.replace('; and','') for x in df['Alias'][index]]\n",
    "            df['Alias'][index] = [x.replace(';','') for x in df['Alias'][index]]\n",
    "            # df['Alias'][index] = df['Alias'][index].apply(lambda x: x.replace(r'\\s-',''))\n",
    "            # df['Alias'][index] = df['Alias'][index].apply(lambda x: x.replace(r'^-',''))\n",
    "            # df['Alias'][index] = df['Alias'][index].apply(lambda x: x.replace(r'^\\s',''))  \n",
    "\n",
    "        # Cleaning Address\n",
    "        # df['Address'] = df['Address'].str.replace('','NaN')\n",
    "        df['Address'][index] = df['Address'][index].strip()\n",
    "\n",
    "        # # Cleaning Subordinate\n",
    "        # df['Subordinate'][index] = df['Subordinate'][index].apply(lambda x: x.replace('\\n',''))\n",
    "        # df['Subordinate'][index] = df['Subordinate'][index].apply(lambda x: x.lstrip('-'))\n",
    "    except:\n",
    "        print(f\"An exception occurred on row {index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 484 entities of type Human.\n",
      "There are 1842 entities of type Firm.\n",
      "There are 125 entities of type Government.\n",
      "There are 247 entities of type Research Institute.\n"
     ]
    }
   ],
   "source": [
    "## Split human and company with identifier as a new column\n",
    "# keywords for firm, government and research institutes\n",
    "firmwords = [# Typical firm suffix\n",
    "            'llc','corp','system','industr','company','ltd','co.','group','factory','enterprise','association','jsc','plant','branch','limited','llp','associates','foundation','inc','sdn bhd','development','headquarter','gmbh','limited','private','oao','ooo','zao','s.a.',' ao',' ab',' oy',' sarl','s.a.l.','trust','fze','fzco','holding','sdn','contracting','complex',' ag','Aktsionernoe Obshchestvo','venture','ltda',\n",
    "            # Geography\n",
    "            'global','beijing','international',\n",
    "            # Industry\n",
    "                # construction and manufacture\n",
    "                'construction', 'steel','engineer','metro','bridge','production','konstrukt','manufactur','fku uprdor','establishment','Al-Qertas','Vangurd Tec','ELPROM','Elara','Moselectronproekt',\n",
    "                # energy\n",
    "                'energy','dietsmannnile','nyakek and sons','Oranto Petroleum','sanco','surgutneftegas','rosneft','chernomorneftegaz',\n",
    "                # pharma\n",
    "                'pharm','ELEMED','medical','Xinjiang Silk Road BGI','rau',\n",
    "                # IT\n",
    "                'comput','semiconductor','electron','micro','radio','microwave','cloud','display','elec','infotec','video','tronic','chip','cyber','angstrem','interscan','Proven Glory','higon','sugon','IFLYTEK','netposa','sensenets','network','dji','kindroid','candiru','corad','MCST Lebedev','NPP Istok','Avanlane','Milur SA','elektronika','SMT-iLogic','streloy','Grant Instrument','elektro','proexcom',\n",
    "                # tech in general\n",
    "                'technolog','integra','tech','solution','tekno','armyfly',\n",
    "                # trade\n",
    "                'trad','service','export','import','logist',\n",
    "                # transportation\n",
    "                'aero','airline','aerospace','shipyard','ship','aircraft','flight','aviation','used car','motors','skylink','vehicle','bike','concord','UEC-Saturn','MPI VOLNA','FASTAIR','Aviazapchast PLC','PT Air',\n",
    "                # chemistry\n",
    "                'chemie','interlab','labinvest','femteco',\n",
    "                # others\n",
    "                'design','field','resort','focus middle east','cosmos','NM-Tekh','TROJANS','Pearl Coral 1173 CC','consulting',\n",
    "             # Firm specific\n",
    "             'huawei', 'nexus','proven honour','gazprom','oceanos','vad, ao','magnetar','apex','melkom','abris','dm link','sngb ao','jadeshine','sputnik','ikco','cytrox','serop','aviton','bitreit','mekom','mces','meo','satco','aquanika','stroygazmontazh','transoil','intelcom','zener','source','yaltinskaya kinodstudiya','otkrytoe aktsionernoe obshchestvo vneshneekonomicheskoe obedinenie tekhnopromeksport','zte','micado','ar kompozit kimya','Regionsnab','Adimir OU','UAB Pella-Fjord','Alfakomponent','The Mother Ark.','Hasa Nederland B.V.','AST Components','kvant',\n",
    "             # AO prefix \n",
    "             'AO Kronshtadt','AO Rubin','AO Aviaagregat','AO PKK Milandr','AO Papilon','AO Geomir','AO SET-1'\n",
    "             ]\n",
    "institutewords = ['university','research center','institute','academy','laborator','nscc','advanced research','development center','TsKB MT Rubin','SDB IRE RAS']\n",
    "govwords =['ministry','desto','paec','cnsim','state ','federal','bureau','intelligence','department','committee','defense','atomic',\"people's republic\",'glavgosekspertiza rossii','crimea','zorsecurity','police']\n",
    "words_list = [firmwords,institutewords,govwords]\n",
    "(list(map(str.lower, words)) for words in words_list)\n",
    "\n",
    "# matching type\n",
    "# Note: in this order to capture gov or institutes wrongly taken as firm\n",
    "df['Type']='Human'\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Name']\n",
    "    if any (firmword in text.lower() for firmword in firmwords):\n",
    "        df.at[index,'Type']='Firm'\n",
    "    if any (govword in text.lower() for govword in govwords):\n",
    "        df.at[index,'Type']='Government'\n",
    "    if any (instituteword in text.lower() for instituteword in institutewords):\n",
    "        df.at[index,'Type']='Research Institute'\n",
    "        \n",
    "# idiosyncratic tuning\n",
    "firm_idio = ['The Jordanian Lebanese Company for Laboratory Instruments S.A.L.','Svyaz Design Bureau, OJSC']\n",
    "df.loc[df['Name'].isin(firm_idio),'Type'] = 'Firm'\n",
    "\n",
    "## Report number each type\n",
    "types = ['Human','Firm','Government','Research Institute']\n",
    "i = 0\n",
    "type_count = types\n",
    "for iter in types:\n",
    "    type_count[i] = df['Type'].str.contains(iter).sum()\n",
    "    print(f\"There are {type_count[i]} entities of type {iter}.\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join identifier\n",
    "# Note: the identifier is from Consolidated Screening List from US government's International Trade Administration on https://www.trade.gov/consolidated-screening-list\n",
    "# Note: the identifier is generally unique to name, but there are still entities with multiple addresses assigned different identifiers. I have manually checked and it appears to be the dataset's problem and they essentially refer to the same entities. Duplicate identifiers are dropped and only the first are kept.\n",
    "idmatch = (pd\n",
    "            .read_csv(\"consolidated2024-01-05.csv\",usecols=['_id','name','source'])\n",
    "            .astype(str)\n",
    "            .drop_duplicates(subset=\"name\",keep='first')\n",
    "            .rename(columns={'name':'Name'})\n",
    "            .set_index('Name'))\n",
    "df = df.merge(idmatch, on='Name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split Fed Register and Effective Date\n",
    "# clean fed register:\n",
    "fed_register_clean = {\n",
    "      '88 FR 121582/27/23.':'88 FR 12158, 2/27/23.',\n",
    "      ' FR FR ': ' FR '\n",
    "}\n",
    "df['temp'] = df['Federal Register citation'].replace(fed_register_clean,regex=True)\n",
    "\n",
    "# get effective date\n",
    "df['Federal Register citation'] = df['temp'].apply(lambda x: re.findall(r'(\\d+ FR \\d+)', x))\n",
    "df['Effective Date'] = df['temp'].apply(lambda x: re.findall(r'(\\d+/\\d+/\\d+)', x))\n",
    "\n",
    "# to check if there is mismatch\n",
    "for index, row in df.iterrows():\n",
    "    if not len(df['Federal Register citation'][index]) == len(df['Effective Date'][index]):\n",
    "         print(index)\n",
    "\n",
    "# explode fed register into panel\n",
    "temp_date = pd.DataFrame(df['Effective Date'])\n",
    "temp_list = df[['Entity','Alias','Subordinate','Address']]\n",
    "df = df.drop(['temp','Effective Date','Alias','Subordinate','Address'],axis=1)\n",
    "columns = df.columns.values.tolist()\n",
    "columns.remove('Federal Register citation')\n",
    "df = (df\n",
    "      .set_index(columns)\n",
    "      .explode('Federal Register citation')\n",
    "      .reset_index()\n",
    ")\n",
    "df['Effective Date'] = temp_date.explode('Effective Date').reset_index()['Effective Date']\n",
    "df = pd.merge(df,temp_list, on='Entity', how='outer')\n",
    "\n",
    "# clean date\n",
    "for index, row in df.iterrows():\n",
    "      try:\n",
    "            temp = datetime.strptime(df['Effective Date'][index],'%m/%d/%y')\n",
    "      except ValueError:\n",
    "            temp = datetime.strptime(df['Effective Date'][index],'%m/%d/%Y')\n",
    "      except TypeError:\n",
    "           continue\n",
    "      df['Effective Date'][index] = temp.strftime('%Y-%m-%d')\n",
    "      \n",
    "\n",
    "# Get year\n",
    "df['Year'] = df['Effective Date'].str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-order dataframe\n",
    "df = (df\n",
    "      .reindex(columns=['_id','Entity','Name','Type','Country','Federal Register citation','Effective Date','Year','License requirement','License review policy','Address','Alias','Subordinate'])\n",
    "      # .loc[:,['Alias','Subordinate']].apply(lambda x: tuple(x))\n",
    "      # .drop_duplicates()\n",
    "      .reset_index(drop=True)\n",
    "      )\n",
    "df.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to a new csv file\n",
    "file = f\"EntityList{date}.csv\"\n",
    "file_cleaned = file.replace('.csv','_cleaned.csv')\n",
    "df.to_csv(f\"{file_cleaned}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
